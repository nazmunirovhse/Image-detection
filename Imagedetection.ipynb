{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Munirov_Nazim_hw3_bonus.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "212w0hi9bND_"
      },
      "source": [
        "## Детекция объектов\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Данные - https://drive.google.com/file/d/1h8XUCFNsBq9w0PXlalJGX34sKmmgfuK9/view?usp=sharing"
      ],
      "metadata": {
        "id": "6xhFYC--_J2R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKmaTEe4Af_t",
        "outputId": "8c9d1ffe-5560-4d32-f694-1191eec34726"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile('/content/drive/MyDrive/archive.zip', 'r') as zip_ref:\n",
        "    zip_ref.extractall('/content')\n"
      ],
      "metadata": {
        "id": "eFtWDAE8AmOS"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install albumentations==0.4.6\n",
        "!pip install --upgrade --force-reinstall --no-deps albumentations\n",
        "!pip install -U albumentations"
      ],
      "metadata": {
        "id": "aWiulvsXjD3K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3ae3a88f-55fb-40e8-b557-de4489649d79"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting albumentations==0.4.6\n",
            "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
            "\u001b[K     |████████████████████████████████| 117 kB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
            "Collecting imgaug>=0.4.0\n",
            "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
            "\u001b[K     |████████████████████████████████| 948 kB 29.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
            "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
            "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.3.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.4.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (4.1.1)\n",
            "Building wheels for collected packages: albumentations\n",
            "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65174 sha256=fb6ec87ab0a63f830b1d21120fe0e90660cf9b305799be3be24087c7c2eff8bd\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
            "Successfully built albumentations\n",
            "Installing collected packages: imgaug, albumentations\n",
            "  Attempting uninstall: imgaug\n",
            "    Found existing installation: imgaug 0.2.9\n",
            "    Uninstalling imgaug-0.2.9:\n",
            "      Successfully uninstalled imgaug-0.2.9\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.1.12\n",
            "    Uninstalling albumentations-0.1.12:\n",
            "      Successfully uninstalled albumentations-0.1.12\n",
            "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting albumentations\n",
            "  Downloading albumentations-1.2.0-py3-none-any.whl (113 kB)\n",
            "\u001b[K     |████████████████████████████████| 113 kB 4.8 MB/s \n",
            "\u001b[?25hInstalling collected packages: albumentations\n",
            "  Attempting uninstall: albumentations\n",
            "    Found existing installation: albumentations 0.4.6\n",
            "    Uninstalling albumentations-0.4.6:\n",
            "      Successfully uninstalled albumentations-0.4.6\n",
            "Successfully installed albumentations-1.2.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: scikit-image<0.19,>=0.16.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (0.18.3)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations) (3.13)\n",
            "Collecting qudida>=0.0.4\n",
            "  Downloading qudida-0.0.4-py3-none-any.whl (3.5 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.4.1)\n",
            "Collecting opencv-python-headless>=4.1.1\n",
            "  Downloading opencv_python_headless-4.6.0.66-cp36-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 48.3 MB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations) (1.21.6)\n",
            "Requirement already satisfied: scikit-learn>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (1.0.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from qudida>=0.0.4->albumentations) (4.1.1)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (1.3.0)\n",
            "Requirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (3.2.2)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (2021.11.2)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (7.1.2)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (2.4.1)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image<0.19,>=0.16.1->albumentations) (2.6.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (1.4.3)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (3.0.9)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib!=3.0.0,>=2.0.0->scikit-image<0.19,>=0.16.1->albumentations) (1.15.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.19.1->qudida>=0.0.4->albumentations) (1.1.0)\n",
            "Installing collected packages: opencv-python-headless, qudida\n",
            "Successfully installed opencv-python-headless-4.6.0.66 qudida-0.0.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install xmltodict"
      ],
      "metadata": {
        "id": "NS6OD5ZAjEeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3b3b562-448a-4875-d8a8-15e48061db02"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xmltodict\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Installing collected packages: xmltodict\n",
            "Successfully installed xmltodict-0.13.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install opencv-python-headless==4.5.2.52"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NDHSHMQ-1Cb3",
        "outputId": "3069d84d-eed5-4352-b57f-e01b7381ac0d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting opencv-python-headless==4.5.2.52\n",
            "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 38.2 MB 1.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from opencv-python-headless==4.5.2.52) (1.21.6)\n",
            "Installing collected packages: opencv-python-headless\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.6.0.66\n",
            "    Uninstalling opencv-python-headless-4.6.0.66:\n",
            "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
            "Successfully installed opencv-python-headless-4.5.2.52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QOr4NI6XbNEK"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import json\n",
        "import glob\n",
        "import cv2\n",
        "import os\n",
        "import torchvision\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import auc\n",
        "from albumentations import pytorch\n",
        "import albumentations as Alb\n",
        "import xmltodict\n",
        "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
        "import albumentations"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O5bt-2SXbNEL"
      },
      "source": [
        "Датасет мы за вас написали."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFeVZS0ebNEL"
      },
      "source": [
        "class2tag = {\"apple\": 1, \"orange\": 2, \"banana\": 3}\n",
        "\n",
        "\n",
        "class FruitDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.images = []\n",
        "        self.annotations = []\n",
        "        self.transform = transform\n",
        "        for annotation in glob.glob(data_dir + \"/*xml\"):\n",
        "            image_fname = os.path.splitext(annotation)[0] + \".jpg\"\n",
        "            self.images.append(cv2.cvtColor(cv2.imread(image_fname), cv2.COLOR_BGR2RGB))\n",
        "            with open(annotation) as f:\n",
        "                annotation_dict = xmltodict.parse(f.read())\n",
        "            bboxes = []\n",
        "            labels = []\n",
        "            objects = annotation_dict[\"annotation\"][\"object\"]\n",
        "            if not isinstance(objects, list):\n",
        "                objects = [objects]\n",
        "            for obj in objects:\n",
        "                bndbox = obj[\"bndbox\"]\n",
        "                bbox = [bndbox[\"xmin\"], bndbox[\"ymin\"], bndbox[\"xmax\"], bndbox[\"ymax\"]]\n",
        "                bbox = list(map(int, bbox))\n",
        "                bboxes.append(torch.tensor(bbox))\n",
        "                labels.append(class2tag[obj[\"name\"]])\n",
        "            self.annotations.append(\n",
        "                {\"boxes\": torch.stack(bboxes).float(), \"labels\": torch.tensor(labels)}\n",
        "            )\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        if self.transform:\n",
        "            res = self.transform(\n",
        "                image=self.images[i],\n",
        "                bboxes=self.annotations[i][\"boxes\"],\n",
        "                labels=self.annotations[i][\"labels\"],\n",
        "            )\n",
        "            return res[\"image\"], {\n",
        "                \"boxes\": torch.tensor(res[\"bboxes\"]),\n",
        "                \"labels\": torch.tensor(res[\"labels\"]),\n",
        "            }\n",
        "        else:\n",
        "            return self.images[i], self.annotations[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCtA2iM2bNEM"
      },
      "source": [
        "Выпишем кое-какую техническую работу, которая уже была на семинаре."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoO_p0KZbNEM"
      },
      "source": [
        "def intersection_over_union(dt_bbox, gt_bbox):\n",
        "\n",
        "\n",
        "    intersection_bbox = np.array(\n",
        "        [\n",
        "            max(dt_bbox[0], gt_bbox[0]),\n",
        "            max(dt_bbox[1], gt_bbox[1]),\n",
        "            min(dt_bbox[2], gt_bbox[2]),\n",
        "            min(dt_bbox[3], gt_bbox[3]),\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    intersection_area = max(intersection_bbox[2] - intersection_bbox[0], 0) * max(\n",
        "        intersection_bbox[3] - intersection_bbox[1], 0\n",
        "    )\n",
        "    area_dt = (dt_bbox[2] - dt_bbox[0]) * (dt_bbox[3] - dt_bbox[1])\n",
        "    area_gt = (gt_bbox[2] - gt_bbox[0]) * (gt_bbox[3] - gt_bbox[1])\n",
        "\n",
        "    union_area = area_dt + area_gt - intersection_area\n",
        "\n",
        "    iou = intersection_area / union_area\n",
        "    return iou\n",
        "\n",
        "def evaluate_sample(target_pred, target_true, iou_threshold=0.5):\n",
        "    gt_bboxes = target_true[\"boxes\"].numpy()\n",
        "    gt_labels = target_true[\"labels\"].numpy()\n",
        "\n",
        "    dt_bboxes = target_pred[\"boxes\"].numpy()\n",
        "    dt_labels = target_pred[\"labels\"].numpy()\n",
        "    dt_scores = target_pred[\"scores\"].numpy()\n",
        "\n",
        "    results = []\n",
        "    for detection_id in range(len(dt_labels)):\n",
        "        dt_bbox = dt_bboxes[detection_id, :]\n",
        "        dt_label = dt_labels[detection_id]\n",
        "        dt_score = dt_scores[detection_id]\n",
        "\n",
        "        detection_result_dict = {\"score\": dt_score}\n",
        "\n",
        "        max_IoU = 0\n",
        "        max_gt_id = -1\n",
        "        for gt_id in range(len(gt_labels)):\n",
        "            gt_bbox = gt_bboxes[gt_id, :]\n",
        "            gt_label = gt_labels[gt_id]\n",
        "\n",
        "            if gt_label != dt_label:\n",
        "                continue\n",
        "\n",
        "            if intersection_over_union(dt_bbox, gt_bbox) > max_IoU:\n",
        "                max_IoU = intersection_over_union(dt_bbox, gt_bbox)\n",
        "                max_gt_id = gt_id\n",
        "\n",
        "        if max_gt_id >= 0 and max_IoU >= iou_threshold:\n",
        "            detection_result_dict[\"TP\"] = 1\n",
        "            gt_labels = np.delete(gt_labels, max_gt_id, axis=0)\n",
        "            gt_bboxes = np.delete(gt_bboxes, max_gt_id, axis=0)\n",
        "\n",
        "        else:\n",
        "            detection_result_dict[\"TP\"] = 0\n",
        "\n",
        "        results.append(detection_result_dict)\n",
        "\n",
        "    return results\n",
        "\n",
        "\n",
        "def evaluate(model, test_loader, device):\n",
        "    results = []\n",
        "    model.eval()\n",
        "    nbr_boxes = 0\n",
        "    with torch.no_grad():\n",
        "        for batch, (images, targets_true) in enumerate(test_loader):\n",
        "            images = list(image.to(device).float() for image in images)\n",
        "            targets_pred = model(images)\n",
        "            targets_true = [\n",
        "                {k: v.cpu().float() for k, v in ta.items()} for t in targets_true\n",
        "            ]\n",
        "            targets_pred = [\n",
        "                {k: v.cpu().float() for k, v in t.items()} for t in targets_pred\n",
        "            ]\n",
        "\n",
        "            for i in range(len(targets_true)):\n",
        "                target_true = targets_true[i]\n",
        "                target_pred = targets_pred[i]\n",
        "                nbr_boxes += target_true[\"labels\"].shape[0]\n",
        "\n",
        "                results.extend(evaluate_sample(target_pred, target_true))\n",
        "\n",
        "    results = sorted(results, key=lambda k: k[\"score\"], reverse=True)\n",
        "\n",
        "    acc_TP = np.zeros(len(results))\n",
        "    acc_FP = np.zeros(len(results))\n",
        "    recall = np.zeros(len(results))\n",
        "    precision = np.zeros(len(results))\n",
        "\n",
        "    if results[0][\"TP\"] == 1:\n",
        "        acc_TP[0] = 1\n",
        "    else:\n",
        "        acc_FP[0] = 1\n",
        "\n",
        "    for i in range(1, len(results)):\n",
        "        acc_TP[i] = results[i][\"TP\"] + acc_TP[i - 1]\n",
        "        acc_FP[i] = (1 - results[i][\"TP\"]) + acc_FP[i - 1]\n",
        "\n",
        "        precision[i] = acc_TP[i] / (acc_TP[i] + acc_FP[i])\n",
        "        recall[i] = acc_TP[i] / nbr_boxes\n",
        "\n",
        "    return auc(recall, precision)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYe2pO1pbNEM"
      },
      "source": [
        "### Создание модели и оптимайзера\n",
        "### Функция обучения модели\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N45-6AgUbNEM"
      },
      "source": [
        "def train_one_epoch(model, train_dataloader, optimizer, device):\n",
        "    model.train()\n",
        "    n = 0\n",
        "    counted_loss = 0 \n",
        "    for images, targets in train_dataloader:\n",
        "        images = list(image.to(device).float() for image in images)\n",
        "        targets = [{i: v.to(device) for i, v in t.items()} for t in targets]\n",
        "\n",
        "        dict_loss = model(images, targets) \n",
        "        losses = sum(loss for loss in dict_loss.values()) \n",
        "\n",
        "        optimizer.zero_grad() \n",
        "        losses.backward() \n",
        "        optimizer.step()\n",
        "\n",
        "        n += 1\n",
        "        counted_loss += float(losses.cpu().detach().numpy()) \n",
        "\n",
        "        if n % 2 == 0:\n",
        "            print(\"Loss value after {} batches is {}\".format(n, round(counted_loss / n, 2))) \n",
        "\n",
        "    return counted_loss\n",
        "\n",
        "\n",
        "\n",
        "def train(model, train_dataloader, val_dataloader, optimizer, device, n_epochs=10):\n",
        "    for epoch in range(n_epochs):\n",
        "        model.eval()\n",
        "        a = evaluate(model, val_dataloader, device=device)\n",
        "        print(\"AUC ON TEST: {.4f}\".format(a))\n",
        "        model.train()\n",
        "        train_one_epoch(model, train_dataloader, optimizer, device=device)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DdjHqoA9bNEN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 414
        },
        "outputId": "f96e5ab7-be0c-446e-b5d1-b6fe49447f8f"
      },
      "source": [
        "train_transform = Alb.Compose([Alb.HorizontalFlip(p=0.4),\n",
        "                               Alb.VerticalFlip(p=0.2),\n",
        "                               Alb.RandomBrightness(limit=(0.1,0.5),p=0.2),\n",
        "                               Alb.RandomContrast(limit=(0.4,0.5),p=0.2),\n",
        "                               Alb.Rotate(limit=90,p=0.1),\n",
        "                               Alb.pytorch.transforms.ToTensorV2()])\n",
        "\n",
        "val_transform = Alb.Compose([Alb.pytorch.transforms.ToTensorV2()], Alb.BboxParams(format='pascal_voc', label_fields=['labels']))\n",
        "\n",
        "train_dataset = FruitDataset(\"/content/train_zip/train\", transform=train_transform)\n",
        "val_dataset = FruitDataset(\"/content/test_zip/test\", transform=val_transform)\n",
        "\n",
        "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
        "params = [p for p in model.parameters() if p.requires_grad]\n",
        "\n",
        "optimizer = torch.optim.SGD(params, lr=0.001, momentum=0.5, weight_decay=0.0001)\n",
        "train_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2, shuffle=False, num_workers=1)\n",
        "val_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=1)\n",
        "n_epochs = 1\n",
        "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
        "\n",
        "train(model, train_dataloader, val_dataloader, optimizer, 'cpu', n_epochs)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/albumentations/augmentations/transforms.py:1615: FutureWarning: This class has been deprecated. Please use RandomBrightnessContrast\n",
            "  FutureWarning,\n",
            "/usr/local/lib/python3.7/dist-packages/albumentations/augmentations/transforms.py:1641: FutureWarning: RandomContrast has been deprecated. Please use RandomBrightnessContrast\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-3953dddca1e5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cuda:0\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-10-edcbdc95cb92>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataloader, val_dataloader, optimizer, device, n_epochs)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"AUC ON TEST: {.4f}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-21-fc63bd3073ad>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(model, test_loader, device)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mtargets_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimages\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             targets_true = [\n\u001b[1;32m     76\u001b[0m                 \u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtargets_true\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 't' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_r5tbqibNEN"
      },
      "source": [
        "__Выведите итоговое качество модели__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LN1hK3-KbNEN"
      },
      "source": [
        "image, labels = next(iter(train_dataset))\n",
        "pred = model(image.unsqueeze(0).to(device))[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mUnFUeqabNEN"
      },
      "source": [
        "from PIL import ImageDraw\n",
        "\n",
        "image = torchvision.transform.ToPILImage()(image)\n",
        "draw = ImageDraw.Draw(image)\n",
        "for box in labels['boxes']:\n",
        "    draw.rectangle([(box[0], box[1]), (box[2], box[3])])\n",
        "    \n",
        "for box in pred['boxes']:\n",
        "    draw.rectangle([(box[0], box[1]), (box[2], box[3])], outline='red')\n",
        "image"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}